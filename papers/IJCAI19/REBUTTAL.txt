




======================================================================================================
======================================================================================================
Review #210401 

Thanks for your thoughtful comments. 

> The idea of using dependencies to provide contrastive explanations
> seems significant to me, and is a good fit with planning search
> spaces. I also appreciate the fact that experiments have been
> conducted to check computational feasibility on a all IPC
> benchamarks. Of course, the usefulness of the work would have to be
> tested by presenting explanations to users and that's lacking for
> now.  It is a bit disappointing that the approach doesn't seem to
> scale to LTL properties, but maybe the trick is not to use
> compilation and just to generate a plan satisfying the LTL formulas
> as part of the test in the algorithm (but then maybe you wouldn't
> have the conflicts implementation for free?)

LTL remains a challenge, yes. Our most recent findings suggest that
there is room for improvement in compilation design. But yes, not
using compilation may be the way to go.

As a side note here: we did not quite get the conflicts
analysis/nogood learning methods "for free". We have added only a
brief description for space reasons, but the extensions, while not
exceedingly deep, are not trivial. We plan to buy additional space for
the final version if accepted, mainly to add the empirical results
from the supplementary material. This will also allow to add a more
detailed description of the nogood learning extensions as well as more
discussion of related work (see next).


> The weakest point of the paper however is the positioning of the
> work with respect to the broader AI literature. How does all this
> relate to areas such as model-based diagnosis, explanations,
> ATMS. For instance, with the exception of the "dependencies" there
> are pretty strong connections between the framework and techniques
> used here and those used in model-based diagnosis to generate all
> minimal diagnoses in circuits or discrete-event systems, see for
> instance the seminal work by Reiter, right up to more recent work by
> Grastien for discrete-event system. In fact, except for the original
> idea of using plan dependencies, the rest of the machinery used,
> including the weakening/strengthening algorithm, the planning
> approach to do the checks, the compilations and so on aren't so
> original.

TODO: Need a reply to this! The reviewer requests one, in
fact. Rebecca, please read the 4 papers the reviewer names here (and
perhaps a few more if relevant); draft an answer, which we can then
discuss on Wednesday. 

I think we should add a related work section like I oririginally
thought; this is the best way I can think of to discuss such more
distant relations, that would be distracting in an introduction (but
we should not mention a new related work section in the rebuttal, or
else the reviewers may say "well this section should have been in the
submission already").

Johan de Kleer: Extending the ATMS. Artif. Intell. 28(2): 163-196 (1986): https://www.sciencedirect.com/science/article/abs/pii/0004370286900810?via%3Dihub

Raymond Reiter: A Theory of Diagnosis from First Principles. Artif. Intell. 32(1): 57-95 (1987) https://www.sciencedirect.com/science/article/pii/0004370287900622

Alban Grastien, Patrik Haslum, Sylvie Thiébaux. Exhaustive diagnosis of discrete event systems through exploration of the hypothesis space. DX-11 http://www.grastien.net/ban/articles/ght-dx11.pdf

Alban Grastien, Patrik Haslum, Sylvie Thiébaux: Conflict-Based Diagnosis of Discrete Event Systems: Theory and Practice. KR 2012 https://www.aaai.org/ocs/index.php/KR/KR12/paper/view/4558


> Before section 2.2: "we cannot have p without forgoing either of q1
> or q2 or q3". Do you mean without forgoing at least one of q1, q2,
> or q3?

Yes that is what we mean. We will reformulate.

> Definition 4: I am having difficulties understanding the
> relationship between =>_suff and {\cal M}_{\Pi}(p) \subseteq {\cal
> M}_{\Pi}(q) in definition 2.

{\cal M}_{\Pi}(p) \subseteq {\cal M}_{\Pi}(q) characterizes
plan-property entailment. =>_suff denotes an easy-to-test sufficient
criterion for such entailment.

> Under Definition 7: I could not understand why "Given the
> restriction to D^{GE}, the equivalence classes in the PDO-GE are
> singletons". Maybe I am overloaded with the notations, or maybe the
> sentence means something different than what I think it means.

In a retricted PDO, we disconsider all entailments outside the given
set D. For D^{GE} we thus consider only entailments of the form "A ==>
not B". So no two formulas in P^{GE} can entail each other.



======================================================================================================
======================================================================================================
Review #256505

Thanks for your thoughtful comments. 

> As far as I understood, the plan explanation approach here described
> depends on the quality of the knowledge base represented by the set
> of plans $\Pi$. This can actually represent a limitation in applying
> this approach to the general case.  How the approach can be used
> inside a decision support system? Does the calculation of $\Pi$
> require a significant time?

As our experiments show, our analysis often is "feasible"
computationally, in the sense of not being more infeasible than the
most closely related classical planning problems.

> Maybe, if significant, the authors can add the computational times
> in the case of the four domains of the empirical evaluation

The empirical results for these four domains are given in the
supplementary material. We plan to buy additional space for the final
version if accepted, to add these results to the paper.

> There is one aspect I would like the authors to comment.  As other
> previous works, this approach is based on computing an explanation a
> posteriori.  Have the authors consider the possibility of creating
> this explanation while generating a plan?  This probably might
> require to change the way plans are generated. And maybe considering
> to have less optimal but explainable by construction plans could be
> acceptable.

TODO: Daniele here is a draft but I'm not sure about it; not sure if I
understand the question well.

Note that a PDO can actually be computed offline, prior to planning,
in principle. The limiting factor in that setting is the set P of plan
properties considered, that must then be fixed a priori. In some
applications at least, it will probably be necessary to identify new
relevant plan properties online as part of the user interaction,
e.g. in an iterative planning process as briefly mentioned in the
introduction. In such a context, new entailment relations must be
computed online. Your question how to combine this with the planning
process is then very relevant. We don't have concrete ideas on this
yet, but it could be an interesting question for future research.

> Minor: in the example I found a bit confusing that the user's
> question refers to a concept, the traffic, that it is not part of
> the model.

We kept the model simple for brevity, but it could easily include traffic information (e.g. google-maps scenario), but we agree mentioning traffic in the question might be confusing, and we'll remove the reference. (TODO: Not sure whether we want to keep this last bit of removing the text).

======================================================================================================
======================================================================================================
Review #261148

Thanks for your thoughtful comments. The open issues you point out are
on the spot in our view. We agree that these things should be done
eventually -- but we respectfully point out that they are beyond scope
of this first paper initiating the work line. As you say yourself, we
managed to fit both the abstract problem description and a specific
instantiation into the paper. With the empirical evaluation of
computational aspects, the paper is full to the brim; indeed the part
of our experiments pertaining to the more powerful action-set
properties had to be moved to the supplementary material (we plan to
buy additional space for the final version, if accepted, to include
these results into the paper).

> My first (and probably the most difficult to tackle) comment is
> that, if this paper is about producing useful explanations for
> users, the experimental work is incomplete at the moment as it does
> not present any user studies. This is the only rigorous way to
> assess whether the method achieves its objectives regarding
> explainability. I am aware this is not trivial, but such studies are
> performed in many fields of CS and can be done by the AI planning
> community too.

We completely agree on that the effectiveness of explanations should be properly assessed by user studies, and indeed we mention this as future work in the conclusion. 
At this stage, in this work we evaluate the feasibility of computing the proposed explanations from a technical point of view. And as a
proof of concept that our answers *may* be suitable for user
inspection in principle, we include in our evaluation the #MUGS data,
which shows that, often, even the full PDO (the full plan space
explanation in our framework) can be compactly described.
The future work will include assessing the quality of the proposed explanations and for that user studies will be conducted.

> Besides, I am not entirely sure that the explanations provided
> within this setting would be that useful for the user. In my view,
> an explanation should offer both a rationale behind a choice and the
> reasoning process that has led to that choice. In the method
> presented by the authors, this reasoning process remains opaque to
> the users, as far as I understand.

In the present paper, yes, we provide merely the plan-property
dependencies themselves. We agree that, in the long term, also the
reasons behind these dependencies should be explainable, answering
"why does this dependency hold true?" questions. In the conclusion, we
mention two concrete ideas to answer such questions. Embarking on
these ideas is among our next steps.

> Also, in this framework, it seems possible to generate complex
> explanations. How do the authors envisage to moderate this
> complexity?

Our #MUGS data shows that, at least in the analysis of goal
dependencies, the full plan-space explanation -- the complete PDO --
can often be communicated compactly. In general, of course, this is
not the case. But for specific questions "why A not B?" the answer is
just a fragment of the PDO (the properties C entailed by B). Beyond
this, in the long term it seems promising to investigate relevance
filters, based e.g. on prior experience with the same user, or on a
preceding interaction context.

> Another problematic part is that the properties are considered an
> input. It will be non-trivial to identify them in advance in such a
> way to predict possible user questions. How do the authors count to
> do that? Are they thinking to do it collaboration with the users?

Automatically finding/mining the plan properties indeed is one of the
most interesting avenues ahead (see our footnote in the
introduction). Possible ideas towards this are, yes,
collaborating/interacting with the user, e.g. in an example-critiquing
fashion; or iteratively broadening a given set P by generalizing from
differences between example plans that do vs. do not satisfy some p
\in P.

> Finally, the framework is instantiated only for one particular
> problem in planning, oversubscription planning. It would be
> interesting to consider another example and show that the same
> concepts work in a different context. I realize this might be
> difficult given the space limitations.

Indeed this is not possible given space. Note that the paper is
already full to the brim and we had to defer part of our empirical
results to the supplementary material.

> Overall, this paper is very interesting, but I believe it is somewhat
> in a preliminary stage, in particular, the experimental part, which
> does not help in assessing the technique in the context in which it is
> situated by the authors themselves, i.e. explainable AI.

In our view, given the complex decision problems involved in our
analysis, a computational evaluation is absolutely
necessary. Furthermore it seems fair to say that, if we had not
performed and included such an evaluation, its absence would have been
reason to reject for most review panels.

> As a minor point, in the introduction there is a misalignment
> between the question “Why do A rather than B?” and “Why does the
> current plan π satisfy p rather than q?”. While if one keeps reading
> the paper, the mismatch gets resolved, I believe it would be
> beneficial to clarify since the beginning that the two questions can
> be mapped into each other within the framework. Finally, related
> work should be discussed more in depth.

Thanks. We will try to improve for a final version of accepted.



======================================================================================================
======================================================================================================
Review #261149

Thanks for your thoughtful comments. 

Regarding our formal framework and MUGS:

In our humble opinion, the generic framework is useful to outline the
approach and problem beyond the special case of goal
dependencies. This also gives much more room for other researchers to
build upon our work/to explore new aspects of the problem addressed,
than a much more narrow paper focussing entirely on goal dependencies.

MUGS lend themselves to addressing powerful plan-property languages
via compilation. We exemplify this with the action-set properties
addressed in Section 4, and briefly discussed in the experiments
section with detailed empirical data given in the supplementary
material. 

Furthermore, LTL can be dealt with by plugging in known compilation
techniques. Indeed we have already implemented this prototypically. We
briefly mention this at the end of Section 4, but it may be too
under-emphasized in the current write-up. We will expand this
discussion if accepted.

> In particular, in the context of the example in Sec.5, it is not
> clear to me why do you not just add the user's requested property to
> the properties already achieved by the plan and output that it is
> impossible to achieve the user's request, if no plan achieving all
> properties can be found? To me this seems more efficient than
> computing all possible MUGS's and then seeing if the user's
> requested property added to the current goal is a MUGS already
> encountered.

The answer given by the MUGS is much more specific. It specifies the
conflicting property (here: transporting all packages with a single
truck). The solvability test you suggest would only say that we cannot
enforce property 5 together with the properties the plan already
has. A goal subset minimization step is necessary to arrive at the
more specific answer. One could, of course, do that goal subset
minimization step on the fly instead, as part of the interaction with
a user. This comes down to computing a subset of the PDO on the
fly. This certainly is one development line for future work.

> "a plan property is a partial function p : T × P → {true, false}":
>     would it be simpler to represent it as a relation?

TODO: This is a really stupid comment. The answer is, of course,
"no". Daniele, should we simply ignore?

> Should "D^{GE} := {( a\in A a,\neg b\in B b) | A \cap B = \emptyset}"
>     be "D^{GE} := {( a\in A a,\neg b\in B b) | A \cap B = \emptyset
>     \wedge (A \cup \B) \subseteq G}" ?

Yes indeed, thanks.

> "We say that p Π-entails q, written..": could you clarify whether
>     "p" can be a general propositional formula? If it can, then you
>     seem to overload the right-arrow between your meta-logic and
>     object-logic, e.g. in "φ ⇒ ψ" vs. "Π |= φ ⇒ ψ" on page 2.

p is a function on plans, that returns a Boolean. That function can in
particular evaluate a formula, so in this sense, as we point out in
the paper below Definition 2, the answer to your question is yes. It
is not clear to us though what you find confusing here. Like we say,
Pi-entailment is essentially like entailment within a knowledge base
(given in the form of Pi). If you can elaborate your concern a bit
more, we will try to address it in our revision.

> What does "\bigwedge_{a\in A} a" mean if "A = \emptyset"

The empty conjunction in our paper means True. We thought this to be
quite common, but actually yes it should be made explicit, so thanks
for pointing it out.

> Proposition 1 seems false to me: suppose A and B are non-empty
>     sets. Suppose that there are no plans that satisfy any "a \in
>     A". Then we have "Π |= /\_{a \in A} ⇒ P", for any P. However, "A
>     \cup B" is not a MUGS, since "A \subset B", but there are not
>     plans achieving all properties in A.

In the situation you describe, we have "A ==> not B", but that
implication is not part of the dominant cPDO as per Definition 4. This
is because each a in A on its own already is unsolvable. In detail: We
use the sufficient criterion ==>_suff for entailment as described at
the end of Section 3.2, saying that larger conjunctions entail smaller
ones and smaller negated conjunctions entail larger ones. Given this,
the entailment "{a} ==> not B" for each a in A subsumes (see Def 4)
the entailment "A ==> not B". Similarly, the entailment "{a} ==> not
{}" subsumes the entailment "{a} ==> not B" for each a in A. So the
dominant PDO-GE contains exactly the entailments "{a} ==> not {}" for
a in A. These are in 1-to-1 correspondence with the MUGS {a} for a in
A.




